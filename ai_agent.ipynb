{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T12:35:15.769247Z",
     "start_time": "2024-04-07T12:35:06.328468Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: llama-index in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (0.10.27)\r\n",
      "Requirement already satisfied: langchain in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (0.1.13)\r\n",
      "Requirement already satisfied: llama-index-llms-openai-like in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (0.2.0)\r\n",
      "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.2.2)\r\n",
      "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.11)\r\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.27 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.10.27)\r\n",
      "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.7)\r\n",
      "Requirement already satisfied: llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.5)\r\n",
      "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.9.48)\r\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.13 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.14)\r\n",
      "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.4)\r\n",
      "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.5)\r\n",
      "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.3)\r\n",
      "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.13)\r\n",
      "Requirement already satisfied: llama-index-readers-llama-parse<0.2.0,>=0.1.2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index) (0.1.4)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (6.0.1)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (2.0.28)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (3.9.3)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (0.6.4)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (1.33)\r\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (0.0.29)\r\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (0.1.33)\r\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (0.0.1)\r\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (0.1.31)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (1.24.4)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (2.6.4)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-llms-openai-like) (4.38.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.21.4)\r\n",
      "Requirement already satisfied: sentence-transformers<3.0.0,>=2.6.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-embeddings-huggingface) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2024.3.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.66.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (4.10.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from huggingface-hub>=0.19.0->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (23.2)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\r\n",
      "Requirement already satisfied: anyio<5,>=3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (3.7.1)\r\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\r\n",
      "Requirement already satisfied: openai>=1.14.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.16.2)\r\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (1.2.14)\r\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (1.0.8)\r\n",
      "Requirement already satisfied: httpx in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (0.27.0)\r\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (0.1.16)\r\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (1.6.0)\r\n",
      "Requirement already satisfied: networkx>=3.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (3.2.1)\r\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (3.8.1)\r\n",
      "Requirement already satisfied: pandas in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (2.2.1)\r\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (10.3.0)\r\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (0.6.0)\r\n",
      "Requirement already satisfied: wrapt in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.27->llama-index) (1.16.0)\r\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\r\n",
      "Requirement already satisfied: pymupdf<2.0.0,>=1.23.21 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\r\n",
      "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.1.0)\r\n",
      "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\r\n",
      "Requirement already satisfied: llama-parse<0.5.0,>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index) (0.4.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.1)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.1.2)\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.4.1.post1)\r\n",
      "Requirement already satisfied: scipy in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.12.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-openai-like) (0.4.2)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.27->llama-index) (1.0.4)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.27->llama-index) (0.14.0)\r\n",
      "Requirement already satisfied: click in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.27->llama-index) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.27->llama-index) (1.3.2)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index) (1.9.0)\r\n",
      "Requirement already satisfied: PyMuPDFb==1.24.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (1.24.1)\r\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.12)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.1.3)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.27->llama-index) (2.9.0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.27->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.27->llama-index) (2024.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from scikit-learn->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (3.4.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.27->llama-index) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers<3.0.0,>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\r\n",
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\r\n",
      "Requirement already satisfied: EbookLib in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (0.18)\r\n",
      "Requirement already satisfied: html2text in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (2024.2.26)\r\n",
      "Requirement already satisfied: lxml in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from EbookLib) (5.1.0)\r\n",
      "Requirement already satisfied: six in /usr/local/Caskroom/miniconda/base/envs/llama/lib/python3.10/site-packages (from EbookLib) (1.16.0)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install llama-index langchain llama-index-llms-openai-like llama-index-embeddings-huggingface -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com\n",
    "! pip install EbookLib html2text -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com\n",
    "! pip install langchain_openai    \n",
    "! pip install unstructured\n",
    "! pip install fastembed\n",
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用Qwen 1.5 14B int4 模型\n",
    "\n",
    "## Llama-index与langchain调用本地模型提供的类OpenAi restful接口"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:09:37.253671Z",
     "start_time": "2024-04-09T01:09:10.064902Z"
    }
   },
   "source": [
    "from llama_index.core.llms import  ChatMessage\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "\n",
    "\n",
    "# from llama_index. import ChatMessage, OpenAILike  \n",
    "\n",
    "li_llm = OpenAILike(  \n",
    "    api_base=\"http://localhost:8000/\",  \n",
    "    timeout=600,  # secs  \n",
    "    api_key=\"loremIpsum\",  \n",
    "    is_chat_model=True,  \n",
    "    context_window=32768,  \n",
    ")  \n",
    "chat_history = [  \n",
    "    ChatMessage(role=\"system\", content=\"你是韩立\"),  \n",
    "    ChatMessage(role=\"user\", content=\"你的道侣是谁？\"),  \n",
    "]  \n",
    "output = li_llm.chat(chat_history)  \n",
    "print(output)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: 在修真世界中，我韩立并未公开提及过道侣。我的修行生涯以自我提升和追求长生为目标，而非世俗的情感纠葛。因此，我没有固定的伴侣或道侣。\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:09:41.741022Z",
     "start_time": "2024-04-09T01:09:37.261603Z"
    }
   },
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage  \n",
    "from langchain_openai import ChatOpenAI  \n",
    "  \n",
    "lc_llm = ChatOpenAI(  \n",
    "    openai_api_base=\"http://localhost:8000/\",  \n",
    "    request_timeout=600,  # secs, I guess.  \n",
    "    openai_api_key=\"loremIpsum\",  \n",
    "    max_tokens=32768,  \n",
    ")  \n",
    "chat_history = [  \n",
    "    SystemMessage(content=\"你是韩立\"),  \n",
    "    HumanMessage(content=\"你的道侣是谁？\"),  \n",
    "]  \n",
    "response = lc_llm(chat_history)\n",
    "print(response.content)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我作为韩立，是修真小说《凡人修仙传》中的主角，我的道侣是南宫婉。在故事中，我们两人经历了许多的磨难和考验，共同成长并最终成为彼此生命中的重要伴侣。\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:09:59.485215Z",
     "start_time": "2024-04-09T01:09:49.484048Z"
    }
   },
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding(api_base=\"http://localhost:8000/\", api_key=\"loremIpsum\")\n",
    "em = embed_model.get_text_embedding(\"你好\")\n",
    "print(em[:4])\n",
    "print(len(em))\n",
    "em = embed_model.get_text_embedding(\"我是韩立\")\n",
    "print(em[:4])\n",
    "print(len(em))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002072902163490653, 0.005953181069344282, 2.810158366628457e-05, -0.004424115642905235]\n",
      "5120\n",
      "[0.007962645031511784, 0.011678668670356274, 0.00018666601681616157, 0.0007532292511314154]\n",
      "5120\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:09:41.860315Z",
     "start_time": "2024-04-09T01:09:41.759131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import Settings\n",
    "Settings.embed_model = embed_model\n",
    "Settings.llm = li_llm\n",
    "\n",
    "# initialize settings (set chunk size)\n",
    "# Settings.chunk_size = 1024\n"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T01:24:23.472365Z",
     "start_time": "2024-04-09T01:24:23.425036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=\"/Users/ezonghu/Downloads/fanren\",\n",
    ").load_data()\n"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:29:56.784990Z",
     "start_time": "2024-04-09T03:29:56.741713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "parser = SentenceSplitter(separator=\" \", chunk_size=128, chunk_overlap=30)\n",
    "nodes = parser.get_nodes_from_documents(documents,)\n"
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:22:47.864685Z",
     "start_time": "2024-04-09T03:22:09.281713Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from llama_index.core import  VectorStoreIndex\n",
    "# global\n",
    "from llama_index.core import Settings\n",
    "Settings.text_splitter = parser\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    transformations=[parser],\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:23:03.315444Z",
     "start_time": "2024-04-09T03:22:56.056800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = index.as_retriever()\n",
    "nodes = retriever.retrieve(\"韩立的妻子\")"
   ],
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:23:41.909265Z",
     "start_time": "2024-04-09T03:23:41.905992Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for n in nodes:\n",
    "    print(n)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 8b5381b6-e21c-4c63-ab49-39af7f0c0427\n",
      "Text: 韩立在进阶大乘后到小灵天将南宫婉寻回。韩立飞升仙界时滞留灵界人族青元宫。\n",
      "Score:  0.835\n",
      "\n",
      "Node ID: 84332603-b9eb-45f1-920c-c1860d92d3f3\n",
      "Text: 道侣 南宫婉\n",
      "韩立双修道侣。掩月宗女修，本命法宝朱雀环，修炼素女轮回功。在血色禁地和韩立合力击杀墨蛟，后因触碰墨蛟淫囊，和韩立颠鸾倒凤。\n",
      "Score:  0.830\n",
      "\n"
     ]
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:27:06.902189Z",
     "start_time": "2024-04-09T03:27:06.884868Z"
    }
   },
   "cell_type": "code",
   "source": "query_engine = index.as_query_engine(llm=li_llm)",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:27:44.981712Z",
     "start_time": "2024-04-09T03:27:22.483453Z"
    }
   },
   "cell_type": "code",
   "source": "response = query_engine.query(\"韩立的妻子\")",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:28:09.761486Z",
     "start_time": "2024-04-09T03:28:09.754525Z"
    }
   },
   "cell_type": "code",
   "source": "print(response)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "南宫婉\n"
     ]
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T03:31:09.478928Z",
     "start_time": "2024-04-09T03:30:41.963215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = query_engine.query(\"韩立的道侣有什么能力\")\n",
    "print(response)\n",
    "response = query_engine.query(\"韩立的妻子有什么能力\")\n",
    "print(response)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "韩立的道侣南宫婉是掩月宗女修，修炼素女轮回功。在故事中，她本命法宝为朱雀环，与韩立合力击杀过墨蛟，并因触碰墨蛟淫囊与韩立有深入的情感交流。\n",
      "韩立的妻子南宫婉是掩月宗的女修，修炼素女轮回功。她的本命法宝是朱雀环。在故事中，她和韩立合力击杀墨蛟，并因某些事件与韩立有亲密互动。\n"
     ]
    }
   ],
   "execution_count": 86
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
